{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¬ End-to-End Research-Grade ML Classification Pipeline\n",
    "\n",
    "**Sections**\n",
    "1. Environment & Reproducibility\n",
    "2. Data Ingestion & Exploratory Data Analysis (EDA)\n",
    "3. Feature Engineering & Preprocessing\n",
    "4. Model Training & Hyperparameter Optimisation (HPO)\n",
    "5. Evaluation â€” Cross-Validation, Curves, Permutation Importance\n",
    "6. Final Model Summary\n",
    "\n",
    "> Dataset: *Breast Cancer Wisconsin (Diagnostic)* â€” a well-understood binary classification benchmark.  \n",
    "> Swap `load_dataset()` in Â§2 with your own `pd.read_csv()` call to adapt instantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Â· Environment & Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ…  Environment ready  |  NumPy 2.4.2  |  Scikit-learn from sklearn\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import warnings, time, json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, cross_validate,\n",
    "    RandomizedSearchCV, learning_curve\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectFromModel, mutual_info_classif\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    RocCurveDisplay, PrecisionRecallDisplay,\n",
    "    ConfusionMatrixDisplay, average_precision_score\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# â”€â”€ Global config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SEED       = 42\n",
    "TEST_SIZE  = 0.20\n",
    "CV_FOLDS   = 5\n",
    "N_ITER_HPO = 40          # RandomizedSearchCV iterations per model\n",
    "FIGSIZE    = (14, 5)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
    "plt.rcParams.update({\"figure.dpi\": 120, \"axes.spines.top\": False, \"axes.spines.right\": False})\n",
    "\n",
    "print(f\"âœ…  Environment ready  |  NumPy {np.__version__}  |  Scikit-learn from sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Â· Data Ingestion & EDA\n",
    "\n",
    "We load the Breast Cancer Wisconsin dataset and perform systematic exploratory analysis covering:\n",
    "- Shape, dtypes, missing-value audit\n",
    "- Class balance\n",
    "- Univariate distributions\n",
    "- Pairwise correlation heatmap\n",
    "- Statistical outlier detection (Z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 2.1  Load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def load_dataset():\n",
    "    \"\"\"Returns X (DataFrame) and y (Series). Swap this function for your data.\"\"\"\n",
    "    raw = load_breast_cancer(as_frame=True)\n",
    "    X = raw.data.copy()\n",
    "    y = raw.target.rename(\"target\")          # 0 = malignant, 1 = benign\n",
    "    return X, y\n",
    "\n",
    "X, y = load_dataset()\n",
    "TARGET_NAMES = {0: \"Malignant\", 1: \"Benign\"}\n",
    "NUM_FEATURES = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "CAT_FEATURES = X.select_dtypes(exclude=\"number\").columns.tolist()\n",
    "\n",
    "print(f\"Dataset shape : {X.shape}\")\n",
    "print(f\"Target        : {y.value_counts().to_dict()}\")\n",
    "print(f\"Numeric cols  : {len(NUM_FEATURES)}  |  Categorical cols : {len(CAT_FEATURES)}\")\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 2.2  Missing value & dtype audit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "audit = pd.DataFrame({\n",
    "    \"dtype\"    : X.dtypes,\n",
    "    \"missing\"  : X.isna().sum(),\n",
    "    \"missing %\" : (X.isna().mean() * 100).round(2),\n",
    "    \"unique\"   : X.nunique(),\n",
    "    \"mean\"     : X.mean().round(3),\n",
    "    \"std\"      : X.std().round(3),\n",
    "})\n",
    "print(audit.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 2.3  Class balance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 2, figsize=FIGSIZE)\n",
    "\n",
    "counts = y.map(TARGET_NAMES).value_counts()\n",
    "axes[0].bar(counts.index, counts.values, color=[\"#e74c3c\", \"#2ecc71\"], edgecolor=\"white\", linewidth=1.5)\n",
    "axes[0].set_title(\"Class Distribution\", fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for i, v in enumerate(counts.values):\n",
    "    axes[0].text(i, v + 2, str(v), ha=\"center\", fontweight=\"bold\")\n",
    "\n",
    "axes[1].pie(counts.values, labels=counts.index, autopct=\"%1.1f%%\",\n",
    "            colors=[\"#e74c3c\", \"#2ecc71\"], startangle=90,\n",
    "            wedgeprops=dict(edgecolor=\"white\", linewidth=2))\n",
    "axes[1].set_title(\"Class Proportion\", fontweight=\"bold\")\n",
    "\n",
    "plt.suptitle(\"Target Variable Analysis\", fontsize=14, fontweight=\"bold\", y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Imbalance ratio (majority/minority): {counts.max()/counts.min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 2.4  Feature distributions (top-15 by variance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "top15 = X[NUM_FEATURES].var().nlargest(15).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(3, 5, figsize=(18, 9))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(top15):\n",
    "    for label, color in [(0, \"#e74c3c\"), (1, \"#2ecc71\")]:\n",
    "        axes[i].hist(X.loc[y == label, col], bins=25, alpha=0.6,\n",
    "                     color=color, label=TARGET_NAMES[label], density=True)\n",
    "    axes[i].set_title(col, fontsize=9)\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "axes[0].legend(fontsize=8)\n",
    "fig.suptitle(\"Feature Distributions by Class (Top 15 by Variance)\", fontsize=13, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 2.5  Correlation heatmap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "corr = X[NUM_FEATURES].corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 13))\n",
    "sns.heatmap(corr, mask=mask, cmap=\"RdYlGn\", center=0, vmin=-1, vmax=1,\n",
    "            annot=False, linewidths=0.3, ax=ax, cbar_kws={\"shrink\": 0.8})\n",
    "ax.set_title(\"Pearson Correlation Matrix\", fontsize=14, fontweight=\"bold\", pad=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Highly correlated pairs\n",
    "high_corr = (corr.abs()\n",
    "             .where(np.tril(np.ones(corr.shape), k=-1).astype(bool))\n",
    "             .stack()\n",
    "             .sort_values(ascending=False))\n",
    "print(\"Top 10 correlated pairs:\")\n",
    "print(high_corr.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 2.6  Outlier detection (Z-score) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "z_scores = np.abs(stats.zscore(X[NUM_FEATURES]))\n",
    "outlier_mask = (z_scores > 3).any(axis=1)\n",
    "print(f\"Samples with |z| > 3 in any feature: {outlier_mask.sum()} ({outlier_mask.mean()*100:.1f}%)\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "outlier_counts = (z_scores > 3).sum(axis=0)\n",
    "outlier_counts.sort_values(ascending=False).head(15).plot(\n",
    "    kind=\"bar\", ax=ax, color=\"#e67e22\", edgecolor=\"white\")\n",
    "ax.set_title(\"Features with Most Outliers (|Z-score| > 3)\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"# Outlier Samples\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Â· Feature Engineering & Preprocessing\n",
    "\n",
    "Pipeline:\n",
    "1. **Imputation** â€” median for numerics, most-frequent for categoricals\n",
    "2. **Scaling** â€” RobustScaler (outlier-resistant)\n",
    "3. **Feature selection** â€” Mutual information + SelectFromModel (ExtraTrees)\n",
    "4. **Train / test split** â€” stratified 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 3.1  Train/test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=SEED, stratify=y\n",
    ")\n",
    "print(f\"Train: {X_train.shape}  |  Test: {X_test.shape}\")\n",
    "print(f\"Train class balance: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test  class balance: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 3.2  Mutual Information â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "mi = mutual_info_classif(X_train[NUM_FEATURES].fillna(X_train[NUM_FEATURES].median()),\n",
    "                          y_train, random_state=SEED)\n",
    "mi_series = pd.Series(mi, index=NUM_FEATURES).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "mi_series.head(20).plot(kind=\"bar\", ax=ax, color=\"#3498db\", edgecolor=\"white\")\n",
    "ax.set_title(\"Mutual Information with Target (Top 20 Features)\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"MI Score\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 3.3  Preprocessing pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  RobustScaler()),\n",
    "])\n",
    "\n",
    "if CAT_FEATURES:\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, NUM_FEATURES),\n",
    "        (\"cat\", categorical_transformer, CAT_FEATURES),\n",
    "    ])\n",
    "else:\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, NUM_FEATURES),\n",
    "    ])\n",
    "\n",
    "# Fit on train, transform both splits\n",
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep  = preprocessor.transform(X_test)\n",
    "print(f\"Preprocessed train shape: {X_train_prep.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 3.4  Feature selection via ExtraTrees importance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "selector = SelectFromModel(\n",
    "    ExtraTreesClassifier(n_estimators=200, random_state=SEED),\n",
    "    threshold=\"mean\"\n",
    ")\n",
    "selector.fit(X_train_prep, y_train)\n",
    "\n",
    "X_train_sel = selector.transform(X_train_prep)\n",
    "X_test_sel  = selector.transform(X_test_prep)\n",
    "\n",
    "n_kept = X_train_sel.shape[1]\n",
    "n_orig = X_train_prep.shape[1]\n",
    "print(f\"Features kept: {n_kept} / {n_orig}  ({n_kept/n_orig*100:.0f}%)\")\n",
    "\n",
    "# Feature importance from selector\n",
    "importances = selector.estimator_.feature_importances_\n",
    "feat_names  = [f\"f{i}\" for i in range(n_orig)]   # generic names post-transform\n",
    "importance_df = (pd.DataFrame({\"feature\": feat_names, \"importance\": importances})\n",
    "                   .sort_values(\"importance\", ascending=False).head(20))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "ax.barh(importance_df[\"feature\"][::-1], importance_df[\"importance\"][::-1],\n",
    "        color=\"#9b59b6\", edgecolor=\"white\")\n",
    "ax.set_title(\"ExtraTrees Feature Importances (Top 20)\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Mean Decrease in Impurity\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Â· Model Training & Hyperparameter Optimisation\n",
    "\n",
    "We train five model families with **RandomizedSearchCV** (stratified CV, optimising ROC-AUC):\n",
    "\n",
    "| Model | Search Space |\n",
    "|---|---|\n",
    "| Logistic Regression | C, penalty, solver |\n",
    "| Random Forest | n_estimators, max_depth, min_samples_split |\n",
    "| Gradient Boosting | n_estimators, learning_rate, max_depth |\n",
    "| Extra Trees | n_estimators, max_features, min_samples_leaf |\n",
    "| SVM | C, kernel, gamma |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 4.1  Search spaces â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "SEARCH_SPACES = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(max_iter=2000, random_state=SEED),\n",
    "        \"params\": {\n",
    "            \"C\"      : loguniform(1e-3, 1e3),\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"solver\" : [\"lbfgs\", \"saga\"],\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "        \"params\": {\n",
    "            \"n_estimators\"    : randint(50, 400),\n",
    "            \"max_depth\"       : [None, 5, 10, 20],\n",
    "            \"min_samples_split\": randint(2, 20),\n",
    "            \"max_features\"    : [\"sqrt\", \"log2\", 0.5],\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=SEED),\n",
    "        \"params\": {\n",
    "            \"n_estimators\" : randint(50, 300),\n",
    "            \"learning_rate\": loguniform(0.01, 0.5),\n",
    "            \"max_depth\"    : randint(2, 8),\n",
    "            \"subsample\"    : [0.7, 0.8, 0.9, 1.0],\n",
    "        }\n",
    "    },\n",
    "    \"ExtraTrees\": {\n",
    "        \"model\": ExtraTreesClassifier(random_state=SEED, n_jobs=-1),\n",
    "        \"params\": {\n",
    "            \"n_estimators\"    : randint(50, 400),\n",
    "            \"max_features\"    : [\"sqrt\", \"log2\", 0.5, 0.8],\n",
    "            \"min_samples_leaf\": randint(1, 10),\n",
    "        }\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"model\": SVC(probability=True, random_state=SEED),\n",
    "        \"params\": {\n",
    "            \"C\"     : loguniform(0.1, 100),\n",
    "            \"kernel\": [\"rbf\", \"poly\"],\n",
    "            \"gamma\" : [\"scale\", \"auto\"],\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "print(f\"HPO config: {N_ITER_HPO} iterations Ã— {CV_FOLDS}-fold CV per model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 4.2  Run HPO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "hpo_results = {}\n",
    "\n",
    "for name, cfg in SEARCH_SPACES.items():\n",
    "    t0 = time.time()\n",
    "    search = RandomizedSearchCV(\n",
    "        cfg[\"model\"], cfg[\"params\"],\n",
    "        n_iter=N_ITER_HPO, cv=cv,\n",
    "        scoring=\"roc_auc\", refit=True,\n",
    "        random_state=SEED, n_jobs=-1, verbose=0\n",
    "    )\n",
    "    search.fit(X_train_sel, y_train)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    hpo_results[name] = {\n",
    "        \"search\"      : search,\n",
    "        \"best_model\"  : search.best_estimator_,\n",
    "        \"best_params\" : search.best_params_,\n",
    "        \"cv_roc_auc\"  : search.best_score_,\n",
    "        \"elapsed_s\"   : elapsed,\n",
    "    }\n",
    "    print(f\"  {name:<22}  CV ROC-AUC = {search.best_score_:.4f}  ({elapsed:.1f}s)\")\n",
    "\n",
    "print(\"\\nâœ…  HPO complete for all models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 4.3  HPO convergence â€“ mean test score vs iteration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, len(hpo_results), figsize=(18, 4), sharey=False)\n",
    "\n",
    "for ax, (name, res) in zip(axes, hpo_results.items()):\n",
    "    cv_df = pd.DataFrame(res[\"search\"].cv_results_)\n",
    "    ax.plot(cv_df[\"mean_test_score\"], \"o-\", ms=3, lw=1.5, color=\"#2980b9\", alpha=0.8)\n",
    "    ax.axhline(res[\"cv_roc_auc\"], color=\"#e74c3c\", ls=\"--\", lw=1.5, label=f\"Best={res['cv_roc_auc']:.4f}\")\n",
    "    ax.set_title(name, fontsize=9, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"ROC-AUC\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "fig.suptitle(\"HPO Convergence (CV ROC-AUC per Iteration)\", fontsize=13, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Â· Evaluation\n",
    "\n",
    "### 5.1  Cross-validated leaderboard\n",
    "### 5.2  Test-set metrics\n",
    "### 5.3  Confusion matrices\n",
    "### 5.4  ROC & Precision-Recall curves\n",
    "### 5.5  Learning curves (bias-variance)\n",
    "### 5.6  Permutation importance (model-agnostic, SHAP-equivalent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 5.1  CV leaderboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "records = []\n",
    "for name, res in hpo_results.items():\n",
    "    cv_out = cross_validate(\n",
    "        res[\"best_model\"], X_train_sel, y_train, cv=cv,\n",
    "        scoring=[\"roc_auc\", \"f1\", \"accuracy\"], n_jobs=-1\n",
    "    )\n",
    "    records.append({\n",
    "        \"Model\"       : name,\n",
    "        \"CV ROC-AUC\"  : f\"{cv_out['test_roc_auc'].mean():.4f} Â± {cv_out['test_roc_auc'].std():.4f}\",\n",
    "        \"CV F1\"       : f\"{cv_out['test_f1'].mean():.4f} Â± {cv_out['test_f1'].std():.4f}\",\n",
    "        \"CV Accuracy\" : f\"{cv_out['test_accuracy'].mean():.4f} Â± {cv_out['test_accuracy'].std():.4f}\",\n",
    "        \"HPO (s)\"     : f\"{res['elapsed_s']:.1f}\",\n",
    "    })\n",
    "    res[\"cv_detailed\"] = cv_out\n",
    "\n",
    "leaderboard = pd.DataFrame(records).sort_values(\"CV ROC-AUC\", ascending=False)\n",
    "leaderboard.index = range(1, len(leaderboard)+1)\n",
    "print(\"=\" * 80)\n",
    "print(\"Cross-Validated Leaderboard\")\n",
    "print(\"=\" * 80)\n",
    "print(leaderboard.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 5.2  Test-set metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "test_records = []\n",
    "for name, res in hpo_results.items():\n",
    "    m = res[\"best_model\"]\n",
    "    y_pred  = m.predict(X_test_sel)\n",
    "    y_proba = m.predict_proba(X_test_sel)[:, 1]\n",
    "    test_records.append({\n",
    "        \"Model\"     : name,\n",
    "        \"Accuracy\"  : accuracy_score(y_test, y_pred),\n",
    "        \"F1\"        : f1_score(y_test, y_pred),\n",
    "        \"ROC-AUC\"   : roc_auc_score(y_test, y_proba),\n",
    "        \"Avg-Prec\"  : average_precision_score(y_test, y_proba),\n",
    "    })\n",
    "\n",
    "test_df = pd.DataFrame(test_records).sort_values(\"ROC-AUC\", ascending=False)\n",
    "test_df.index = range(1, len(test_df)+1)\n",
    "test_df[[\"Accuracy\",\"F1\",\"ROC-AUC\",\"Avg-Prec\"]] = test_df[[\"Accuracy\",\"F1\",\"ROC-AUC\",\"Avg-Prec\"]].round(4)\n",
    "print(test_df.to_string())\n",
    "\n",
    "# Best model\n",
    "best_name = test_df.iloc[0][\"Model\"]\n",
    "best_model = hpo_results[best_name][\"best_model\"]\n",
    "print(f\"\\nğŸ†  Best model on test set: {best_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 5.3  Confusion matrices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, len(hpo_results), figsize=(20, 4))\n",
    "\n",
    "for ax, (name, res) in zip(axes, hpo_results.items()):\n",
    "    y_pred = res[\"best_model\"].predict(X_test_sel)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=[\"Mal\", \"Ben\"], yticklabels=[\"Mal\", \"Ben\"],\n",
    "                cbar=False, linewidths=0.5)\n",
    "    ax.set_title(f\"{name}\\nAcc={accuracy_score(y_test,y_pred):.3f}\", fontsize=9)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "fig.suptitle(\"Confusion Matrices (Test Set)\", fontsize=13, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 5.4  ROC & Precision-Recall curves â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "colors = [\"#2980b9\",\"#27ae60\",\"#e74c3c\",\"#9b59b6\",\"#e67e22\"]\n",
    "\n",
    "for (name, res), color in zip(hpo_results.items(), colors):\n",
    "    y_proba = res[\"best_model\"].predict_proba(X_test_sel)[:, 1]\n",
    "    RocCurveDisplay.from_predictions(y_test, y_proba, name=name, ax=axes[0], color=color, alpha=0.85)\n",
    "    PrecisionRecallDisplay.from_predictions(y_test, y_proba, name=name, ax=axes[1], color=color, alpha=0.85)\n",
    "\n",
    "axes[0].plot([0,1],[0,1],\"k--\",lw=1)\n",
    "axes[0].set_title(\"ROC Curves (Test Set)\", fontweight=\"bold\")\n",
    "axes[1].set_title(\"Precision-Recall Curves (Test Set)\", fontweight=\"bold\")\n",
    "axes[0].legend(loc=\"lower right\", fontsize=8)\n",
    "axes[1].legend(loc=\"upper right\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 5.5  Learning curves (best model) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_model, X_train_sel, y_train,\n",
    "    cv=cv, scoring=\"roc_auc\",\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1, shuffle=True, random_state=SEED\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "ax.fill_between(train_sizes,\n",
    "                train_scores.mean(1) - train_scores.std(1),\n",
    "                train_scores.mean(1) + train_scores.std(1), alpha=0.15, color=\"#2980b9\")\n",
    "ax.fill_between(train_sizes,\n",
    "                val_scores.mean(1)   - val_scores.std(1),\n",
    "                val_scores.mean(1)   + val_scores.std(1),   alpha=0.15, color=\"#e74c3c\")\n",
    "ax.plot(train_sizes, train_scores.mean(1), \"o-\", color=\"#2980b9\", label=\"Train ROC-AUC\")\n",
    "ax.plot(train_sizes, val_scores.mean(1),   \"o-\", color=\"#e74c3c\", label=\"Val ROC-AUC\")\n",
    "ax.set_xlabel(\"Training samples\")\n",
    "ax.set_ylabel(\"ROC-AUC\")\n",
    "ax.set_title(f\"Learning Curve â€” {best_name}\", fontweight=\"bold\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0.7, 1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "gap = train_scores.mean(1)[-1] - val_scores.mean(1)[-1]\n",
    "print(f\"Train-Val gap at full data: {gap:.4f}  â†’ {'âš  slight overfit' if gap > 0.03 else 'âœ… well-generalised'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 5.6  Permutation importance (model-agnostic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "perm = permutation_importance(\n",
    "    best_model, X_test_sel, y_test,\n",
    "    n_repeats=30, random_state=SEED,\n",
    "    scoring=\"roc_auc\", n_jobs=-1\n",
    ")\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    \"feature\"   : [f\"f{i}\" for i in range(X_test_sel.shape[1])],\n",
    "    \"mean\"      : perm.importances_mean,\n",
    "    \"std\"       : perm.importances_std,\n",
    "}).sort_values(\"mean\", ascending=False).head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "ax.barh(perm_df[\"feature\"][::-1], perm_df[\"mean\"][::-1],\n",
    "        xerr=perm_df[\"std\"][::-1], color=\"#1abc9c\", edgecolor=\"white\",\n",
    "        error_kw=dict(ecolor=\"gray\", capsize=3))\n",
    "ax.set_xlabel(\"Mean decrease in ROC-AUC (Â± std)\")\n",
    "ax.set_title(f\"Permutation Importance â€” {best_name}  (n_repeats=30)\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 most important features:\")\n",
    "print(perm_df.head(5)[[\"feature\",\"mean\",\"std\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 5.7  Detailed classification report (best model) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_pred = best_model.predict(X_test_sel)\n",
    "print(f\"Classification Report â€” {best_name}\")\n",
    "print(\"=\" * 55)\n",
    "print(classification_report(y_test, y_pred, target_names=list(TARGET_NAMES.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Â· Final Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# â”€â”€ 6.1  Summary card â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_pred  = best_model.predict(X_test_sel)\n",
    "y_proba = best_model.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "summary = {\n",
    "    \"Best Model\"        : best_name,\n",
    "    \"Best Hyperparams\"  : hpo_results[best_name][\"best_params\"],\n",
    "    \"Test Accuracy\"     : f\"{accuracy_score(y_test, y_pred):.4f}\",\n",
    "    \"Test F1\"           : f\"{f1_score(y_test, y_pred):.4f}\",\n",
    "    \"Test ROC-AUC\"      : f\"{roc_auc_score(y_test, y_proba):.4f}\",\n",
    "    \"Test Avg Precision\": f\"{average_precision_score(y_test, y_proba):.4f}\",\n",
    "    \"Features (orig)\"   : X.shape[1],\n",
    "    \"Features (selected)\": int(X_train_sel.shape[1]),\n",
    "    \"Train samples\"     : len(X_train),\n",
    "    \"Test samples\"      : len(X_test),\n",
    "    \"CV Folds\"          : CV_FOLDS,\n",
    "    \"HPO Iterations\"    : N_ITER_HPO,\n",
    "}\n",
    "\n",
    "print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
    "print(\"â•‘           FINAL PIPELINE SUMMARY                        â•‘\")\n",
    "print(\"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\")\n",
    "for k, v in summary.items():\n",
    "    if k == \"Best Hyperparams\":\n",
    "        print(f\"â•‘  {k:<28}: (see below)               â•‘\")\n",
    "    else:\n",
    "        print(f\"â•‘  {k:<28}: {str(v):<28} â•‘\")\n",
    "print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for k, v in hpo_results[best_name][\"best_params\"].items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Pipeline Checklist\n",
    "\n",
    "| Step | Status |\n",
    "|---|---|\n",
    "| Data ingestion | âœ… |\n",
    "| Missing value audit | âœ… |\n",
    "| EDA (distributions, correlation, outliers) | âœ… |\n",
    "| Median imputation + RobustScaler | âœ… |\n",
    "| Mutual information feature analysis | âœ… |\n",
    "| ExtraTrees feature selection | âœ… |\n",
    "| 5-model HPO (RandomizedSearchCV) | âœ… |\n",
    "| Stratified K-Fold cross-validation | âœ… |\n",
    "| Confusion matrices | âœ… |\n",
    "| ROC & Precision-Recall curves | âœ… |\n",
    "| Learning curves | âœ… |\n",
    "| Permutation importance | âœ… |\n",
    "\n",
    "> **To adapt to your own data:** replace `load_dataset()` in Â§2 with `pd.read_csv(...)`, update `NUM_FEATURES` / `CAT_FEATURES`, and adjust `TARGET_NAMES`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
